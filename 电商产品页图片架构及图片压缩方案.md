产品图对电商非常重要，一方面图片质量和加载速度影响产品页到订单页转化（转化率），另一方面也占据着cdn流量费用的大头，是一个成本。以一个aleax排名前2000的电商网站来说：pc\m\app\站外引用，每年的图片cdn费用在200W左右。

#### 图片中心  

目前图片中心一方面提供基础的restful接口供各个业务处理图片(上传/切图等，2台，不做存储)，另一方面通过rsync命令同步到存储服务器（一台大存储配置，作为cdn源站）。这架构很原始，不是分布式而是集中式的，带来2个问题：存储集中式有限制，无法扩展；同步遇到跨机房延迟问题，在1S左右。

考虑过fastdfs这类的分布式存储，但分布式存储路径都是随机hash的，无法兼容业务（指定路径和文件名），虽然有折衷的方案实现，但是比较繁琐。二是有尺寸切图、旋转图、水印图各种需求，比如images/201708/ef/150356774756_thumb_600x800_rotate_90.jpg这种复合指令，即切图又旋转，既然fastfds做存储，配合nginx的一些模块可以实现，但是为了灵活应对业务，我们选择在URL中注入单个参数或者多个组合参数,GET请求通到nginx过滤然后rewrite到后台处理返回。

图片(产品/评论/反馈/运单/营销)越来越多，集中式存储肯定无法应对。目前一个方案是：对URL一致性hash，拿到一台机器，和处理缓存key相似的逻辑。这也是简单的分布式存储，也对高可用提出了非常高的标准，算法怎么设计到单台机器或多台机器新老图片冷热不均也需要好好考虑。在调研amazon s3 的时候，对数据冷热不均会有不同的收费标准。

####图片压缩

图片压缩就一个要求：大小降低，但图片不能失真。

压缩主要是产品图和banner图，编辑人员后台上传的产品图都是高清，尺寸在1100×1465，大小一般在800–900kb， 甚至1M多，通过2-3次压缩最终能降到200–400kb，而图片质量在肉眼看来无明显变化。

图片上传保存的时候，imagick库可以设置压缩比：

```Imagick::setImageCompressionQuality```

这个压缩比，我们无法对每张图片准确设置，设置的小图片会糊，设置了大的压缩没效果，后来找到一种平衡，就是先获取压缩比，比如低于90，不压缩，大于90则压缩为0.85*原压缩值：

```
$compress =Imagick::getImageCompressionQuality;
 
if($compress > 90){
 
   $compress = 0.85 * $compress;
 
   Imagick::setImageCompressionQuality($compress);
 
}
```

这个0.85的压缩比没数据支撑，只是个想当然的取值，仍然有的图会糊。最后我们采取的Google刚开源的软件

> https://github.com/google/guetzli。

七牛有图片瘦身功能，不知道七牛怎么实现的。

Google的无损压缩质量很高，但是很耗CPU和时间，这些问题在issue里面是反馈最多的。我们测试的时候：压缩一张图片基本会占用一个100%CPU，时间也在分钟级左右。这就意味着32核的机器，最大75%利用率也就是24个cpu，也就只能压缩24张，每天1500张图片怎么处理？只能多台机器异步跑，同时收集汇总压缩失败信息。

![image](https://raw.githubusercontent.com/DoDoneIt/Develop-blog-img/master/QQ%E6%88%AA%E5%9B%BE20170828103532.png)

通过2个多月的线上观察，产品详情页的图片大小明显降低，在pv环比增长13%下，cdn费用无显著变化，随着线上已经缩的图占比越来越多，效果会更明显。更重要是图片大小的降低，提高了首页和产品页的加载速度

产品页图片的优化还有空间，一个产品详情页至少4张全尺寸大图，后期会根据屏幕分辨率显示不同尺寸的图（600x，800x，1200x），而不是全尺寸大图，这样产品页的图片加载会更小，相应的速度也会提升。

 ![image](https://raw.githubusercontent.com/DoDoneIt/Develop-blog-img/master/QQ截图20170828101651-1024x350.png)

#### 上传和压缩主要流程 

 1.业务上传成功后push进redis待压缩队列

```php 

app('redis')->rPush('compress_queue','');//推

 ```           

 2.长进程脚本pull队列并调用shell脚本执行压缩

 一个压缩进程会占用一个满cpu，所有在脚本拉取压缩队列，我们会判断当前执行进程数，最大化利用cpu同时避免机器满负载运行

```php

//取当前机器cpu核数
exec("cat /proc/cpuinfo| grep 'processor'| wc -l",$cpu,$cpu_status);
$process = floor($cpu['0'] * 0.75);
while(1){
    usleep(200000);//避免长进程循环redis挂掉
    app('redis')->connect("imgdeal.redis.com","6379");
    //当前在执行的压缩进程数小于3/4 cpu核数,则取出执行,避免机器满负载
    exec("ps auxf|grep 'guetzli'|grep -v grep|wc -l",$a,$status);
    if($status==0 && $a['0'] < $process ){
        try {
        	//TODO
            //调用shell，shell进行压缩处理和处理结果收集
            $command = 'bash /opt/shell/1_compress.sh >/dev/null 2>>/tmp/test.log &';
            exec($command);
            app('redis')->close();
        }catch (Exception $e){
        }
    }else{
        app('redis')->close();
        continue;
    }
}

```        
 
3.shell脚本执行guetzli压缩，并把结果推进数据汇总队列

```php

#!/bin/bash

if [ $# != 4 ] ; then
    echo "args num error!"
    exit 1;
fi

prefix_path=$1
add_time=$2
src_file=$3
dst_file=$4

key="preocess_log_`date -I`"

origin_size=`stat -c '%s' $src_file`

compress_log="`/usr/local/guetzli/bin/Release/guetzli $src_file $dst_file 2>&1`"
is_success=$?
compress_end_time="`date '+%Y-%m-%d %H:%M:%S'`"
compress_size=`stat -c '%s' $dst_file`

mv_log="`mv -f $dst_file $src_file 2>&1`"
mv_success=$?

value=""

#推进压缩结果队列
/usr/local/redis/bin/redis-cli -h imgdeal.redis.com -p 6379 rpush "$key" "$value" >/dev/null 2>&1

```

 每日邮件汇总：

 ![image](https://raw.githubusercontent.com/DoDoneIt/Develop-blog-img/master/QQ%E6%88%AA%E5%9B%BE20170828101505.png)
 
 
 